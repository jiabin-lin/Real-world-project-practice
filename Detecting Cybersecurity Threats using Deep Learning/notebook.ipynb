{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d547b11f-1ed0-4d71-9b39-514ba85079ec",
   "metadata": {},
   "source": [
    "![cyber_photo](cyber_photo.jpg)\n",
    "\n",
    "Cyber threats are a growing concern for organizations worldwide. These threats take many forms, including malware, phishing, and denial-of-service (DOS) attacks, compromising sensitive information and disrupting operations. The increasing sophistication and frequency of these attacks make it imperative for organizations to adopt advanced security measures. Traditional threat detection methods often fall short due to their inability to adapt to new and evolving threats. This is where deep learning models come into play.\n",
    "\n",
    "Deep learning models can analyze vast amounts of data and identify patterns that may not be immediately obvious to human analysts. By leveraging these models, organizations can proactively detect and mitigate cyber threats, safeguarding their sensitive information and ensuring operational continuity.\n",
    "\n",
    "As a cybersecurity analyst, you identify and mitigate these threats. In this project, you will design and implement a deep learning model to detect cyber threats. The BETH dataset simulates real-world logs, providing a rich source of information for training and testing your model. The data has already undergone preprocessing, and we have a target label, `sus_label`, indicating whether an event is malicious (1) or benign (0).\n",
    "\n",
    "By successfully developing this model, you will contribute to enhancing cybersecurity measures and protecting organizations from potentially devastating cyber attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2967110-9515-4a1b-8ab6-f7bfd5c84d83",
   "metadata": {},
   "source": [
    "\n",
    "### The Data\n",
    "\n",
    "| Column     | Description              |\n",
    "|------------|--------------------------|\n",
    "|`processId`|The unique identifier for the process that generated the event - int64 |\n",
    "|`threadId`|ID for the thread spawning the log - int64|\n",
    "|`parentProcessId`|Label for the process spawning this log - int64|\n",
    "|`userId`|ID of user spawning the log|Numerical - int64|\n",
    "|`mountNamespace`|Mounting restrictions the process log works within - int64|\n",
    "|`argsNum`|Number of arguments passed to the event - int64|\n",
    "|`returnValue`|Value returned from the event log (usually 0) - int64|\n",
    "|`sus_label`|Binary label as suspicous event (1 is suspicious, 0 is not) - int64|\n",
    "\n",
    "More information on the dataset: [BETH dataset](accreditation.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35558034-b7b7-4ab7-8d59-5e6ed281f838",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 500,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.4.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.23.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.11.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.6.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->torchmetrics) (0.38.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Make sure to run this cell to use torchmetrics. If you cannot use pip install to install the torchmetrics, you can use sklearn.\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3121b05-9873-431d-812c-62bceffbf1b3",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 44,
    "lastExecutedAt": 1721636772106,
    "lastExecutedByKernel": "6ccb1964-cd32-460b-9f84-9658941f880c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import required libraries\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as functional\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset\nimport torch.optim as optim\nfrom torchmetrics import Accuracy\n# from sklearn.metrics import accuracy_score  # uncomment to use sklearn"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy\n",
    "# from sklearn.metrics import accuracy_score  # uncomment to use sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08bfe2bf-3132-490e-9c16-9026f82b8d73",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 371,
    "lastExecutedAt": 1721636772478,
    "lastExecutedByKernel": "6ccb1964-cd32-460b-9f84-9658941f880c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Load preprocessed data\ntrain_df = pd.read_csv('labelled_train.csv')\ntest_df = pd.read_csv('labelled_test.csv')\nval_df = pd.read_csv('labelled_validation.csv')\n\n# View the first 5 rows of training set\ntrain_df.head()",
    "outputsMetadata": {
     "0": {
      "height": 188,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/com.datacamp.data-table.v2+json": {
       "table": {
        "data": {
         "argsNum": [
          5,
          1,
          0,
          2,
          4
         ],
         "index": [
          0,
          1,
          2,
          3,
          4
         ],
         "mountNamespace": [
          4026532231,
          4026532231,
          4026532231,
          4026531840,
          4026531840
         ],
         "parentProcessId": [
          1,
          1,
          1,
          7341,
          7341
         ],
         "processId": [
          381,
          381,
          381,
          7347,
          7347
         ],
         "returnValue": [
          0,
          0,
          0,
          -2,
          0
         ],
         "sus_label": [
          1,
          1,
          1,
          1,
          1
         ],
         "threadId": [
          7337,
          7337,
          7337,
          7347,
          7347
         ],
         "userId": [
          100,
          100,
          100,
          0,
          0
         ]
        },
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "processId",
           "type": "integer"
          },
          {
           "name": "threadId",
           "type": "integer"
          },
          {
           "name": "parentProcessId",
           "type": "integer"
          },
          {
           "name": "userId",
           "type": "integer"
          },
          {
           "name": "mountNamespace",
           "type": "integer"
          },
          {
           "name": "argsNum",
           "type": "integer"
          },
          {
           "name": "returnValue",
           "type": "integer"
          },
          {
           "name": "sus_label",
           "type": "integer"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 5,
       "truncation_type": null
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processId</th>\n",
       "      <th>threadId</th>\n",
       "      <th>parentProcessId</th>\n",
       "      <th>userId</th>\n",
       "      <th>mountNamespace</th>\n",
       "      <th>argsNum</th>\n",
       "      <th>returnValue</th>\n",
       "      <th>sus_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>381</td>\n",
       "      <td>7337</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>4026532231</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>381</td>\n",
       "      <td>7337</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>4026532231</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>381</td>\n",
       "      <td>7337</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>4026532231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7347</td>\n",
       "      <td>7347</td>\n",
       "      <td>7341</td>\n",
       "      <td>0</td>\n",
       "      <td>4026531840</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7347</td>\n",
       "      <td>7347</td>\n",
       "      <td>7341</td>\n",
       "      <td>0</td>\n",
       "      <td>4026531840</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   processId  threadId  parentProcessId  ...  argsNum  returnValue  sus_label\n",
       "0        381      7337                1  ...        5            0          1\n",
       "1        381      7337                1  ...        1            0          1\n",
       "2        381      7337                1  ...        0            0          1\n",
       "3       7347      7347             7341  ...        2           -2          1\n",
       "4       7347      7347             7341  ...        4            0          1\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "train_df = pd.read_csv('labelled_train.csv')\n",
    "test_df = pd.read_csv('labelled_test.csv')\n",
    "val_df = pd.read_csv('labelled_validation.csv')\n",
    "\n",
    "# View the first 5 rows of training set\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a6908f6-bdf0-45d1-afd0-84b26c7e4865",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1721636772530,
    "lastExecutedByKernel": "6ccb1964-cd32-460b-9f84-9658941f880c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Start coding here\n# Use as many cells as you need"
   },
   "outputs": [],
   "source": [
    "# Start coding here\n",
    "# Use as many cells as you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec17dd3-3531-43a8-9a24-9f3c60c24430",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af922b9d-ead9-4779-b509-852e29f62722",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 79,
    "lastExecutedAt": 1721636772610,
    "lastExecutedByKernel": "6ccb1964-cd32-460b-9f84-9658941f880c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Create a custom dataset class\nclass TabularDataset(Dataset):\n    def __init__(self, data, targets):\n        self.data = data\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.targets[idx]\n\n# Separate features and labels for training, testing, and validation sets\nX_train = train_df.drop('sus_label', axis=1).values\ny_train = train_df['sus_label'].values\nX_test = test_df.drop('sus_label', axis=1).values\ny_test = test_df['sus_label'].values\nX_val = val_df.drop('sus_label', axis=1).values\ny_val = val_df['sus_label'].values\n\n# Initialize the StandardScaler\nscaler = StandardScaler()\n\n# Fit the scaler on the training data and transform the training data\nX_train = scaler.fit_transform(X_train)\n\n# Transform the test and validation data using the fitted scaler\nX_test = scaler.transform(X_test)\nX_val = scaler.transform(X_val)\n\n# Convert the numpy arrays to PyTorch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\nX_val_tensor = torch.tensor(X_val, dtype=torch.float32)\ny_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n\ntrain_data = TabularDataset(X_train_tensor, y_train_tensor)\nval_data = TabularDataset(X_val_tensor, y_val_tensor)\n\ndataloader = DataLoader(train_data, batch_size = 20, shuffle=True)\nval_loader = DataLoader(val_data, batch_size = 20, shuffle=True)"
   },
   "outputs": [],
   "source": [
    "# Create a custom dataset class\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "# Separate features and labels for training, testing, and validation sets\n",
    "X_train = train_df.drop('sus_label', axis=1).values\n",
    "y_train = train_df['sus_label'].values\n",
    "X_test = test_df.drop('sus_label', axis=1).values\n",
    "y_test = test_df['sus_label'].values\n",
    "X_val = val_df.drop('sus_label', axis=1).values\n",
    "y_val = val_df['sus_label'].values\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform the training data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test and validation data using the fitted scaler\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Convert the numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_data = TabularDataset(X_train_tensor, y_train_tensor)\n",
    "val_data = TabularDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "dataloader = DataLoader(train_data, batch_size = 20, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size = 20, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a7951-1790-458c-ab51-a857014203a3",
   "metadata": {},
   "source": [
    "#### Define a neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "947f4fce-b244-49c2-b6b2-e1aada7ee61d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 50,
    "lastExecutedAt": 1721636772662,
    "lastExecutedByKernel": "6ccb1964-cd32-460b-9f84-9658941f880c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import torch\nimport torch.nn as nn\n\nclass NetworkTrafficClassifier(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(NetworkTrafficClassifier, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.fc2 = nn.Linear(hidden_size, output_size)\n        \n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = torch.sigmoid(self.fc2(x))\n        return x\n",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NetworkTrafficClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NetworkTrafficClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3362f9b3-b75c-46d6-9f62-a94dc00f8170",
   "metadata": {},
   "source": [
    "#### Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8897796-257e-451c-adb4-9fc29ceab1ee",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 437,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.01574795674453181\n",
      "Epoch: 2, Loss: 0.01574655414205907\n",
      "Epoch: 3, Loss: 0.015746554142020017\n",
      "Epoch: 4, Loss: 0.015746579479289504\n",
      "Epoch: 5, Loss: 0.01574655414280106\n",
      "Epoch: 6, Loss: 0.015746554142020017\n",
      "Epoch: 7, Loss: 0.015746554142722954\n",
      "Epoch: 8, Loss: 0.01574655414186381\n",
      "Epoch: 9, Loss: 0.015746554141590444\n",
      "Epoch: 10, Loss: 0.01574655414280106\n",
      "Epoch: 11, Loss: 0.015746554142215277\n",
      "Epoch: 12, Loss: 0.015746554142566746\n",
      "Epoch: 13, Loss: 0.01574655414088751\n",
      "Epoch: 14, Loss: 0.015746554141785704\n",
      "Epoch: 15, Loss: 0.01574655414229338\n",
      "Epoch: 16, Loss: 0.015746554141941912\n",
      "Epoch: 17, Loss: 0.01574655414225433\n",
      "Epoch: 18, Loss: 0.015746554142566746\n",
      "Epoch: 19, Loss: 0.01574655414205907\n",
      "Epoch: 20, Loss: 0.015746554141199926\n"
     ]
    }
   ],
   "source": [
    "# Assuming train_df and num_classes are defined elsewhere in the notebook\n",
    "feature_size = len(train_df.columns) - 1\n",
    "hidden_size = 32\n",
    "target_size = train_df['sus_label'].nunique()\n",
    "\n",
    "model = NetworkTrafficClassifier(input_size = feature_size, hidden_size = hidden_size, output_size = target_size)\n",
    "\n",
    "lr = 0.05\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "for i in range(epochs):\n",
    "    running_loss, num_processed = 0, 0 \n",
    "    for inputs, labels in dataloader:\n",
    "        model.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels.long().squeeze())  # Ensure labels are of type LongTensor and squeezed\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_processed += len(inputs)\n",
    "    print(f\"Epoch: {i+1}, Loss: {running_loss/num_processed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d902feda-ff53-4ff0-b743-75ab71267cc9",
   "metadata": {},
   "source": [
    "#### Evaluate the model based on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44abd15a-68c7-48ea-a6a3-f19136046c10",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 6357,
    "lastExecutedAt": 1721637246973,
    "lastExecutedByKernel": "6ccb1964-cd32-460b-9f84-9658941f880c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "accuracy_metric = Accuracy(task='binary', num_classes=2)\n\nmodel.eval()\npredicted = []\n\nfor i, (inputs, labels) in enumerate(val_loader):\n    output = model(inputs)\n    predicted_classes = torch.argmax(output, dim=-1)\n    # cat = torch.argmax(output, dim = -1)\n    predicted.extend(predicted_classes)\n    accuracy_metric(predicted_classes, labels.squeeze())  # Fix: Squeeze labels to match shape\n\n#output\nval_accuracy = accuracy_metric.compute().item()\n# val_accuracy"
   },
   "outputs": [],
   "source": [
    "accuracy_metric = Accuracy(task='binary', num_classes=2)\n",
    "\n",
    "model.eval()\n",
    "predicted = []\n",
    "\n",
    "for i, (inputs, labels) in enumerate(val_loader):\n",
    "    output = model(inputs)\n",
    "    predicted_classes = torch.argmax(output, dim=-1)\n",
    "    # cat = torch.argmax(output, dim = -1)\n",
    "    predicted.extend(predicted_classes)\n",
    "    accuracy_metric(predicted_classes, labels.squeeze())  # Fix: Squeeze labels to match shape\n",
    "\n",
    "#output\n",
    "val_accuracy = accuracy_metric.compute().item()\n",
    "# val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87910b62-7ddf-40b5-9cc7-93aada8ff9f0",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1721637247022,
    "lastExecutedByKernel": "6ccb1964-cd32-460b-9f84-9658941f880c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "val_accuracy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9958405494689941"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
